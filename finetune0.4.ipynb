{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11499\n",
      "11825\n",
      "2253216\n"
     ]
    }
   ],
   "source": [
    "import torch as pt\n",
    "\n",
    "\n",
    "mols_test = pt.load('./data/mine/test_11499.pt')\n",
    "print(len(mols_test))\n",
    "mols_val = pt.load('./data/mine/val_11825.pt')\n",
    "print(len(mols_val))\n",
    "mols_all = pt.load('./data/mine/mols_all.pt')\n",
    "print(len(mols_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mass_all = np.array([float(mol.metadata['nominal_mass']) for mol in mols_all])\n",
    "mass_test = np.array([float(mol.metadata['nominal_mass']) for mol in mols_test])\n",
    "mass_val = np.array([float(mol.metadata['nominal_mass']) for mol in mols_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.data import SpecDataset, SpecDataset_finetune, collate_fun_emb, collate_fun_finetune\n",
    "\n",
    "\n",
    "dataset_lib = SpecDataset(mols_all)\n",
    "loader_lib = DataLoader(dataset_lib, batch_size=2048, shuffle=False,\n",
    "                        num_workers=8, collate_fn=collate_fun_emb)\n",
    "dataset_val = SpecDataset(mols_val)\n",
    "loader_val = DataLoader(dataset_val, batch_size=2048, shuffle=False,\n",
    "                        num_workers=8, collate_fn=collate_fun_emb)\n",
    "dataset_test = SpecDataset(mols_test)\n",
    "loader_test = DataLoader(dataset_test, batch_size=2048, shuffle=False,\n",
    "                        num_workers=8, collate_fn=collate_fun_emb)\n",
    "dataset_finetune = SpecDataset_finetune((mols_val, mols_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Finetune_epoch1======================================\n",
      "Searching time:  0:00:01.613016\n",
      "Validation library\n",
      "Top1 hit rate: 43.89%\n",
      "Top10 hit rate: 82.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 312/349 [00:05<00:00, 91.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9904110113779704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:06<00:00, 49.97batch/s]\n",
      " 89%|████████▉ | 312/349 [00:06<00:00, 86.51batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9859908823172251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:07<00:00, 45.48batch/s]\n",
      " 90%|█████████ | 315/349 [00:07<00:00, 87.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9802273492018382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:08<00:00, 39.27batch/s]\n",
      " 91%|█████████ | 316/349 [00:07<00:00, 86.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9670295816659927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:08<00:00, 40.06batch/s]\n",
      " 89%|████████▊ | 309/349 [00:07<00:00, 85.25batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9505515831708908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:08<00:00, 39.27batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Test_epoch1======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching time:  0:00:01.574095\n",
      "Expanded library\n",
      "Top1 hit rate: 42.83%\n",
      "Top10 hit rate: 83.90%\n",
      "Searching time:  0:00:01.495802\n",
      "In-silico library\n",
      "Top1 hit rate: 43.11%\n",
      "Top10 hit rate: 84.33%\n",
      "With Mass:\n",
      "Searching time:  0:00:01.567990\n",
      "Expanded library\n",
      "Top1 hit rate: 50.80%\n",
      "Top10 hit rate: 90.93%\n",
      "Searching time:  0:00:01.491236\n",
      "In-silico library\n",
      "Top1 hit rate: 51.15%\n",
      "Top10 hit rate: 91.20%\n",
      "================================================================================================\n",
      "==================================Finetune_epoch2======================================\n",
      "Searching time:  0:00:01.608956\n",
      "Validation library\n",
      "Top1 hit rate: 53.82%\n",
      "Top10 hit rate: 91.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 311/366 [00:06<00:00, 89.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.976724262436231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:08<00:00, 44.85batch/s]\n",
      " 86%|████████▌ | 313/366 [00:07<00:00, 87.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9719607601563136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:08<00:00, 41.08batch/s]\n",
      " 84%|████████▍ | 308/366 [00:07<00:00, 84.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9674709280331929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:08<00:00, 41.54batch/s]\n",
      " 86%|████████▌ | 314/366 [00:07<00:00, 83.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.965538561741511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:09<00:00, 40.18batch/s]\n",
      " 85%|████████▍ | 310/366 [00:07<00:00, 80.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9619528927405675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:09<00:00, 39.25batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Test_epoch2======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching time:  0:00:01.582163\n",
      "Expanded library\n",
      "Top1 hit rate: 43.31%\n",
      "Top10 hit rate: 84.16%\n",
      "Searching time:  0:00:01.503104\n",
      "In-silico library\n",
      "Top1 hit rate: 43.58%\n",
      "Top10 hit rate: 84.52%\n",
      "With Mass:\n",
      "Searching time:  0:00:01.568346\n",
      "Expanded library\n",
      "Top1 hit rate: 51.52%\n",
      "Top10 hit rate: 91.59%\n",
      "Searching time:  0:00:01.491743\n",
      "In-silico library\n",
      "Top1 hit rate: 51.87%\n",
      "Top10 hit rate: 91.95%\n",
      "================================================================================================\n",
      "==================================Finetune_epoch3======================================\n",
      "Searching time:  0:00:01.630666\n",
      "Validation library\n",
      "Top1 hit rate: 58.49%\n",
      "Top10 hit rate: 93.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 313/368 [00:05<00:00, 88.22batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9660742004712423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:07<00:00, 47.16batch/s]\n",
      " 86%|████████▌ | 316/368 [00:07<00:00, 92.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9614268527428309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:08<00:00, 41.46batch/s]\n",
      " 86%|████████▌ | 317/368 [00:07<00:00, 86.32batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9588480953375499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:09<00:00, 39.06batch/s]\n",
      " 86%|████████▌ | 316/368 [00:07<00:00, 88.67batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9558197156588236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:09<00:00, 39.47batch/s]\n",
      " 85%|████████▍ | 312/368 [00:07<00:00, 85.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.9522421328226726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [00:09<00:00, 39.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Test_epoch3======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching time:  0:00:01.556401\n",
      "Expanded library\n",
      "Top1 hit rate: 42.18%\n",
      "Top10 hit rate: 83.54%\n",
      "Searching time:  0:00:01.506676\n",
      "In-silico library\n",
      "Top1 hit rate: 42.45%\n",
      "Top10 hit rate: 83.92%\n",
      "With Mass:\n",
      "Searching time:  0:00:01.573775\n",
      "Expanded library\n",
      "Top1 hit rate: 50.44%\n",
      "Top10 hit rate: 91.38%\n",
      "Searching time:  0:00:01.501219\n",
      "In-silico library\n",
      "Top1 hit rate: 50.91%\n",
      "Top10 hit rate: 91.76%\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch as pt\n",
    "import torch.optim as optim\n",
    "from utils.model import Spec2Emb\n",
    "from tqdm import tqdm\n",
    "from utils.tools import gen_embeddings, build_idx, evaluate, find_nearest_hit_nhit, save_model\n",
    "\n",
    "\n",
    "gpu = 6\n",
    "model = Spec2Emb().to(gpu)\n",
    "model.load_state_dict(pt.load('./model/base_peak0.01_epoch4.pth', map_location='cpu'))\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "f = open('ft_p0.4_mass.txt', 'w') # ft：finetune，base指未更改模型结构\n",
    "model_name = 'ft_p0.4_mass'\n",
    "max_metrics = {'expanded': [0, 0], 'insilico': [0, 0], 'expanded_mass': [0, 0], 'insilico_mass': [0, 0]}\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    print(f'==================================Finetune_epoch{epoch+1}======================================')\n",
    "    f.write('\\nFinetune_epoch%d\\n' % (epoch+1))\n",
    "    embeddings_lib = gen_embeddings(model, loader_lib, gpu, power=0.4)\n",
    "    embeddings_val = gen_embeddings(model, loader_val, gpu, power=0.4)\n",
    "    embeddings_lib[:, -1] = mass_all\n",
    "    embeddings_val[:, -1] = mass_val\n",
    "    I, _ = build_idx(embeddings_lib, embeddings_val, gpu, topk=200) # 内置清缓存\n",
    "    top1_val, top10_val = evaluate(mols_val, I, mols_all, f, 'Validation')\n",
    "    vals, hits, nhits = find_nearest_hit_nhit(I, mols_val, mols_all)\n",
    "    dataset_ft = SpecDataset_finetune(dataset_finetune, mapping=(vals, hits, nhits))\n",
    "    loader_ft = DataLoader(dataset_ft, batch_size, shuffle=True, num_workers=8, collate_fn=collate_fun_finetune)\n",
    "    model.train()\n",
    "    for j in range(5):\n",
    "        finetune_loss = []\n",
    "        for i, Data in enumerate(tqdm(loader_ft, unit='batch')):\n",
    "            Data = [d.to(gpu) for data in Data for d in data]\n",
    "            optimizer.zero_grad()\n",
    "            loss = model((Data[:3], Data[3:6], Data[6:9]), mode='finetune', power=0.4)\n",
    "            finetune_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) %300 ==0:\n",
    "                loss = np.mean(finetune_loss)\n",
    "                print(f'Total Loss: {loss}')\n",
    "                finetune_loss = []\n",
    "\n",
    "    print(f'===================================Test_epoch{epoch+1}======================================')\n",
    "    f.write('\\n\\nTest_epoch%d\\n' % (epoch+1))\n",
    "    embeddings_lib = gen_embeddings(model, loader_lib, gpu, power=0.4) \n",
    "    embeddings_test = gen_embeddings(model, loader_test, gpu, power=0.4)\n",
    "    I_expand, _ = build_idx(embeddings_lib, embeddings_test, gpu, topk=200)\n",
    "    top1_expand, top10_expand = evaluate(mols_test, I_expand, mols_all, f, 'expanded')\n",
    "    if top1_expand > max_metrics['expand'][0] and top10_expand > max_metrics['expanded'][1]:\n",
    "        max_metrics['expand'] = [top1_expand, top10_expand]\n",
    "        save_model(model, model_name, epoch)\n",
    "    I_insilico, _ = build_idx(embeddings_lib[:2146690], embeddings_test, gpu, topk=200)\n",
    "    top1_insilico, top10_insilico = evaluate(mols_test, I_insilico, mols_all, f, 'insilico')\n",
    "    if top1_insilico > max_metrics['insilico'][0] and top10_insilico > max_metrics['insilico'][1]:\n",
    "        max_metrics['insilico'] = [top1_insilico, top10_insilico]\n",
    "        save_model(model, model_name, epoch)\n",
    "    print(f'\\nWith Mass:')\n",
    "    f.write('With Mass:\\n')\n",
    "    embeddings_lib[:, -1] = mass_all\n",
    "    embeddings_test[:, -1] = mass_test\n",
    "    I_expand, _ = build_idx(embeddings_lib, embeddings_test, gpu, topk=200)\n",
    "    top1_expand, top10_expand = evaluate(mols_test, I_expand, mols_all, f, 'expanded')\n",
    "    if top1_expand > max_metrics['expanded_mass'][0] and top10_expand > max_metrics['expanded_mass'][1]:\n",
    "        max_metrics['expanded_mass'] = [top1_expand, top10_expand]\n",
    "        save_model(model, model_name, epoch)\n",
    "    I_insilico, _ = build_idx(embeddings_lib[:2146690], embeddings_test, gpu, topk=200)\n",
    "    top1_insilico, top10_insilico = evaluate(mols_test, I_insilico, mols_all, f, 'insilico')\n",
    "    if top1_insilico > max_metrics['insilico_mass'][0] and top10_insilico > max_metrics['insilico_mass'][1]:\n",
    "        max_metrics['insilico_mass'] = [top1_insilico, top10_insilico]\n",
    "        save_model(model, model_name, epoch)\n",
    "    print(f'================================================================================================')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
